{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Cleaned Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare event dataset for analysis by cleaning up and determining assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/sql_past_shows_df.pkl','rb') as read_file:\n",
    "    ticket_sales_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 751 entries, 0 to 750\n",
      "Data columns (total 18 columns):\n",
      "start_date          751 non-null object\n",
      "end_date            751 non-null object\n",
      "year                751 non-null int64\n",
      "month               751 non-null object\n",
      "season              751 non-null object\n",
      "day_of_week         751 non-null object\n",
      "time_of_week        751 non-null object\n",
      "num_shows           751 non-null int64\n",
      "show_type           751 non-null object\n",
      "headliner           751 non-null object\n",
      "support             579 non-null object\n",
      "num_support         751 non-null int64\n",
      "tickets_sold        751 non-null int64\n",
      "gross_usd           751 non-null float64\n",
      "venue_capacity      751 non-null int64\n",
      "percentage_sold     751 non-null float64\n",
      "ticket_price_min    751 non-null float64\n",
      "ticket_price_max    751 non-null float64\n",
      "dtypes: float64(4), int64(5), object(9)\n",
      "memory usage: 105.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ticket_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split multiple show rows into multiple rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Assumption**: \n",
    "    - The dataset contains rows that represent multiple shows for a single artist (e.g. if an artist plays two shows and the start date is 01/02, the end date would be 01/03).  It's ideal to have each row of the dataset represent one show, so these rows will be split as necessary into multiple rows.  Ticket sales, gross revenue, etc. will be averaged across these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate duplicate rows for consecutive shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up dataframe by num_shows (1, 2 or 3)\n",
    "\n",
    "ticket_sales_1show = ticket_sales_df[ticket_sales_df['num_shows'] == 1]\n",
    "\n",
    "ticket_sales_2shows = ticket_sales_df[ticket_sales_df['num_shows'] == 2]\n",
    "ticket_sales_x2 = pd.concat([ticket_sales_2shows]*2).sort_values(by='start_date').reset_index(drop=True)\n",
    "\n",
    "ticket_sales_3shows = ticket_sales_df[ticket_sales_df['num_shows'] == 3]\n",
    "ticket_sales_x3 = pd.concat([ticket_sales_3shows]*3).sort_values(by='start_date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Fix the dates where an artist played two nights.\n",
    "\n",
    "ticket_sales_x2['start_date'][1::2] = ticket_sales_x2['end_date'][1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2012, 2, 12),\n",
       " datetime.date(2012, 11, 25),\n",
       " datetime.date(2018, 8, 8),\n",
       " datetime.date(2018, 9, 10)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all dates are correct.\n",
    "# Looks like there were 4 errors: 2012-02-12, 2012-11-25, 08-08-2018, and 09-10-2018.\n",
    "\n",
    "dup_list = []\n",
    "dup_dates = ticket_sales_x2.pivot_table(index=['start_date'], aggfunc='size')\n",
    "\n",
    "for index, value in dup_dates.items():\n",
    "    if value == 2:\n",
    "        dup_list.append(index)\n",
    "\n",
    "dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a quick google search:\n",
    "# duplicate 2012-02-12 show is 2012-02-13\n",
    "# duplicate 2012-11-25 show is 2012-11-26\n",
    "# duplicate 2018-08-08 show is 2018-08-07\n",
    "# duplicate 2018-09-10 show is 2018-09-11\n",
    "\n",
    "ticket_sales_x2.loc[29, 'start_date'] = dt.date(2012, 2, 13)\n",
    "ticket_sales_x2.loc[41, 'start_date'] = dt.date(2012, 11, 26)\n",
    "ticket_sales_x2.loc[140, 'start_date'] = dt.date(2018, 8, 7)\n",
    "ticket_sales_x2.loc[147, 'start_date'] = dt.date(2018, 9, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Fix the dates where an artist played three nights.\n",
    "\n",
    "ticket_sales_x3['start_date'][1::3] += dt.timedelta(days=1)\n",
    "ticket_sales_x3['start_date'][2::3] = ticket_sales_x3['end_date'][2::3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all dates are correct. Looks like they are (i.e. no duplicates).\n",
    "\n",
    "dup_dates = ticket_sales_x3.pivot_table(index=['start_date'], aggfunc='size')\n",
    "dup_dates.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up ticket sales and gross USD across the multiple shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that will find the average tickets sold, \n",
    "# gross USD, and gross gate across multiple shows.\n",
    "\n",
    "def multiple_show_means(df):\n",
    "    \n",
    "    df['tickets_sold'] = df['tickets_sold']/df['num_shows']\n",
    "    df['gross_usd'] = df['gross_usd']/df['num_shows']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_sales_x3 = multiple_show_means(ticket_sales_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_sales_x2 = multiple_show_means(ticket_sales_x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update main dataframe with new rows and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the separate dataframes into a single dataframe, and delete \n",
    "# the \"end_date\" column as it's no longer necessary.\n",
    "\n",
    "multiple_shows_df = ticket_sales_x3.append(ticket_sales_x2)\n",
    "ticket_clean_df = ticket_sales_1show.append(multiple_shows_df).sort_values(by='start_date').reset_index(drop=True)\n",
    "del ticket_clean_df['end_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 859 entries, 0 to 858\n",
      "Data columns (total 17 columns):\n",
      "start_date          859 non-null object\n",
      "year                859 non-null int64\n",
      "month               859 non-null object\n",
      "season              859 non-null object\n",
      "day_of_week         859 non-null object\n",
      "time_of_week        859 non-null object\n",
      "num_shows           859 non-null int64\n",
      "show_type           859 non-null object\n",
      "headliner           859 non-null object\n",
      "support             644 non-null object\n",
      "num_support         859 non-null int64\n",
      "tickets_sold        859 non-null float64\n",
      "gross_usd           859 non-null float64\n",
      "venue_capacity      859 non-null int64\n",
      "percentage_sold     859 non-null float64\n",
      "ticket_price_min    859 non-null float64\n",
      "ticket_price_max    859 non-null float64\n",
      "dtypes: float64(5), int64(4), object(8)\n",
      "memory usage: 114.2+ KB\n"
     ]
    }
   ],
   "source": [
    "ticket_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update date-related features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The date features are incorrect for the newly-generated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add year, month, and day of week columns to dataframe.\n",
    "date = pd.to_datetime(ticket_clean_df.start_date, format='%Y-%m-%d')\n",
    "ticket_clean_df['year'] = date.dt.year\n",
    "ticket_clean_df['month'] = date.dt.month\n",
    "ticket_clean_df['day_of_week'] = date.dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_helper(month_num):\n",
    "    if month_num == 1:\n",
    "        return 'January'\n",
    "    elif month_num == 2:\n",
    "        return 'February'\n",
    "    elif month_num == 3:\n",
    "        return 'March'\n",
    "    elif month_num == 4:\n",
    "        return 'April'\n",
    "    elif month_num == 5:\n",
    "        return 'May'\n",
    "    elif month_num == 6:\n",
    "        return 'June'\n",
    "    elif month_num == 7:\n",
    "        return 'July'\n",
    "    elif month_num == 8:\n",
    "        return 'August'\n",
    "    elif month_num == 9:\n",
    "        return 'September'\n",
    "    elif month_num == 10:\n",
    "        return 'October'\n",
    "    elif month_num == 11:\n",
    "        return 'November'\n",
    "    else:\n",
    "        return 'December'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df['month'] = ticket_clean_df['month'].apply(month_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create season column:\n",
    "\n",
    "def season_helper(month):\n",
    "    if month in ['December', 'January', 'February']:\n",
    "        return 'Winter'\n",
    "    if month in ['March', 'April', 'May']:\n",
    "        return 'Spring'\n",
    "    if month in ['June', 'July', 'August']:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df['season'] = ticket_clean_df['month'].apply(season_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dow_helper(dow_num):\n",
    "    if dow_num == 0:\n",
    "        return 'Sunday'\n",
    "    elif dow_num == 1:\n",
    "        return 'Monday'\n",
    "    elif dow_num == 2:\n",
    "        return 'Tuesday'\n",
    "    elif dow_num == 3:\n",
    "        return 'Wednesday'\n",
    "    elif dow_num == 4:\n",
    "        return 'Thursday'\n",
    "    elif dow_num == 5:\n",
    "        return 'Friday'\n",
    "    else:\n",
    "        return 'Saturday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df['day_of_week'] = ticket_clean_df['day_of_week'].apply(dow_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weekday vs weekend column\n",
    "\n",
    "def week_helper(day):\n",
    "\n",
    "     if day in ['Thursday','Friday','Saturday']:\n",
    "        return 'Weekend'\n",
    "     else:\n",
    "        return 'Weekday'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df['time_of_week'] = ticket_clean_df['day_of_week'].apply(week_helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Cleaning of Band Names (to facilitate future web scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df.loc[612, 'Headliner'] = 'Peppa Pig'\n",
    "ticket_clean_df.loc[687, 'Headliner'] = 'Miguel'\n",
    "ticket_clean_df.loc[796, 'Headliner'] = 'Lauryn Hill'\n",
    "ticket_clean_df.loc[806, 'Headliner'] = 'Ella Mai'\n",
    "ticket_clean_df.loc[807, 'Headliner'] = 'Neal Schon'\n",
    "ticket_clean_df.loc[833, 'Headliner'] = 'Ella Mai'\n",
    "ticket_clean_df.loc[834, 'Headliner'] = \"Chris D'Elia\"\n",
    "ticket_clean_df.loc[840, 'Headliner'] = 'The Specials'\n",
    "ticket_clean_df.loc[841, 'Headliner'] = 'Little Feat'\n",
    "ticket_clean_df.loc[844, 'Headliner'] = 'Bela Fleck & The Flecktones'\n",
    "ticket_clean_df.loc[845, 'Headliner'] = 'Local Natives'\n",
    "ticket_clean_df.loc[853, 'Headliner'] = 'Paul Simon'\n",
    "ticket_clean_df.loc[854, 'Headliner'] = 'Kirk Franklin'\n",
    "ticket_clean_df.loc[855, 'Headliner'] = 'Daniel Caesar'\n",
    "ticket_clean_df.loc[857, 'Headliner'] = 'King Crimson'\n",
    "ticket_clean_df.loc[858, 'Headliner'] = 'King Crimson'\n",
    "ticket_clean_df = ticket_clean_df.drop(ticket_clean_df.index[725])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cleaning portion is complete for event dataset.\n",
    "- **See \"Artist_Feature_Web_Scraping\" notebook for second half of data compilation.**\n",
    "    - In that notebook, artist features will be scraped and added to the event dataset to create complete final dataset.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
