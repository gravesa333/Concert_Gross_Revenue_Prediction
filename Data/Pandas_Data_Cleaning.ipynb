{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Cleaned Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Prepare event dataset for analysis by cleaning up and determining assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_sales_df = pd.read_csv(r'fox-theater-ticket-sales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 893 entries, 0 to 892\n",
      "Data columns (total 18 columns):\n",
      "Start Date          893 non-null object\n",
      "End Date            751 non-null object\n",
      "Num Shows           893 non-null int64\n",
      "Headliner           893 non-null object\n",
      "Support             579 non-null object\n",
      "Tickets Sold        751 non-null float64\n",
      "Gross USD           751 non-null float64\n",
      "Gross Gate          751 non-null float64\n",
      "Currency            751 non-null object\n",
      "Venue Capacity      751 non-null float64\n",
      "Percentage Sold     893 non-null float64\n",
      "Ticket Price Min    751 non-null float64\n",
      "Ticket Price Max    751 non-null float64\n",
      "Venue Name          893 non-null object\n",
      "Venue City          893 non-null object\n",
      "Venue State         893 non-null object\n",
      "Venue Country       893 non-null object\n",
      "Promoter            739 non-null object\n",
      "dtypes: float64(7), int64(1), object(10)\n",
      "memory usage: 125.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ticket_sales_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Date Features to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = pd.to_datetime(ticket_sales_df['Start_Date'], format='%m/%d/%Y')\n",
    "# end_date = pd.to_datetime(ticket_sales_df['End_Date'], format='%m/%d/%Y')\n",
    "ticket_sales_df['Start Date'] = pd.to_datetime(ticket_sales_df['Start Date'], format='%m/%d/%Y').dt.date\n",
    "ticket_sales_df['End Date'] = pd.to_datetime(ticket_sales_df['End Date'], format='%m/%d/%Y').dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split multiple show rows into multiple rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Assumption**: \n",
    "    - The dataset contains rows that represent multiple shows for a single artist (e.g. if an artist plays two shows and the start date is 01/02, the end date would be 01/03).  It's ideal to have each row of the dataset represent one show, so these rows will be split as necessary into multiple rows.  Ticket sales, gross revenue, etc. will be averaged across these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate duplicate rows for consecutive shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up dataframe by num_shows (1, 2 or 3)\n",
    "\n",
    "ticket_sales_1show = ticket_sales_df[ticket_sales_df['Num Shows'] == 1]\n",
    "\n",
    "ticket_sales_2shows = ticket_sales_df[ticket_sales_df['Num Shows'] == 2]\n",
    "ticket_sales_x2 = pd.concat([ticket_sales_2shows]*2).sort_values(by='Start Date').reset_index(drop=True)\n",
    "\n",
    "ticket_sales_3shows = ticket_sales_df[ticket_sales_df['Num Shows'] == 3]\n",
    "ticket_sales_x3 = pd.concat([ticket_sales_3shows]*3).sort_values(by='Start Date').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Fix the dates where an artist played two nights.\n",
    "\n",
    "ticket_sales_x2['Start Date'][1::2] = ticket_sales_x2['End Date'][1::2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2012, 2, 12),\n",
       " datetime.date(2012, 11, 25),\n",
       " datetime.date(2018, 8, 8),\n",
       " datetime.date(2018, 9, 10)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all dates are correct.\n",
    "# Looks like there were 4 errors: 2012-02-12, 2012-11-25, 08-08-2018, and 09-10-2018.\n",
    "\n",
    "dup_list = []\n",
    "dup_dates = ticket_sales_x2.pivot_table(index=['Start Date'], aggfunc='size')\n",
    "\n",
    "for index, value in dup_dates.items():\n",
    "    if value == 2:\n",
    "        dup_list.append(index)\n",
    "\n",
    "dup_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing a quick google search:\n",
    "# duplicate 2012-02-12 show is 2012-02-13\n",
    "# duplicate 2012-11-25 show is 2012-11-26\n",
    "# duplicate 2018-08-08 show is 2018-08-07\n",
    "# duplicate 2018-09-10 show is 2018-09-11\n",
    "\n",
    "ticket_sales_x2.loc[29, 'Start Date'] = dt.date(2012, 2, 13)\n",
    "ticket_sales_x2.loc[41, 'Start Date'] = dt.date(2012, 11, 26)\n",
    "ticket_sales_x2.loc[140, 'Start Date'] = dt.date(2018, 8, 7)\n",
    "ticket_sales_x2.loc[147, 'Start Date'] = dt.date(2018, 9, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/andrewgraves/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Fix the dates where an artist played three nights.\n",
    "\n",
    "ticket_sales_x3['Start Date'][1::3] += dt.timedelta(days=1)\n",
    "ticket_sales_x3['Start Date'][2::3] = ticket_sales_x3['End Date'][2::3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify all dates are correct. Looks like they are (i.e. no duplicates).\n",
    "\n",
    "dup_dates = ticket_sales_x3.pivot_table(index=['Start Date'], aggfunc='size')\n",
    "dup_dates.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up ticket sales and gross USD across the multiple shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that will find the average tickets sold, \n",
    "# gross USD, and gross gate across multiple shows.\n",
    "\n",
    "def multiple_show_means(df):\n",
    "    \n",
    "    df['Tickets Sold'] = df['Tickets Sold']/df['Num Shows']\n",
    "    df['Gross USD'] = df['Gross USD']/df['Num Shows']\n",
    "    df['Gross Gate']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_sales_x3 = multiple_show_means(ticket_sales_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_sales_x2 = multiple_show_means(ticket_sales_x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update main dataframe with new rows and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the separate dataframes into a single dataframe, and delete \n",
    "# the \"end_date\" column as it's no longer necessary.\n",
    "\n",
    "multiple_shows_df = ticket_sales_x3.append(ticket_sales_x2)\n",
    "ticket_clean_df = ticket_sales_1show.append(multiple_shows_df).sort_values(by='Start Date').reset_index(drop=True)\n",
    "del ticket_clean_df['End Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1001 entries, 0 to 1000\n",
      "Data columns (total 17 columns):\n",
      "Start Date          1001 non-null object\n",
      "Num Shows           1001 non-null int64\n",
      "Headliner           1001 non-null object\n",
      "Support             644 non-null object\n",
      "Tickets Sold        859 non-null float64\n",
      "Gross USD           859 non-null float64\n",
      "Gross Gate          859 non-null float64\n",
      "Currency            859 non-null object\n",
      "Venue Capacity      859 non-null float64\n",
      "Percentage Sold     1001 non-null float64\n",
      "Ticket Price Min    859 non-null float64\n",
      "Ticket Price Max    859 non-null float64\n",
      "Venue Name          1001 non-null object\n",
      "Venue City          1001 non-null object\n",
      "Venue State         1001 non-null object\n",
      "Venue Country       1001 non-null object\n",
      "Promoter            833 non-null object\n",
      "dtypes: float64(7), int64(1), object(9)\n",
      "memory usage: 133.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ticket_clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace Festival Names with Actual Headliners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 9 nights of the Noise Pop Festival throughout the dataset. In order to facilitate web scraping of artist data, the headliner name will be replaced with the actual headliner from each corresponding night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df.loc[83, 'Headliner'] = 'Yoko Ono'\n",
    "ticket_clean_df.loc[86, 'Headliner'] = 'The Magnetic Fields'\n",
    "ticket_clean_df.loc[157, 'Headliner'] = 'Yo La Tengo'\n",
    "ticket_clean_df.loc[218, 'Headliner'] = 'Porter Robinson'\n",
    "ticket_clean_df.loc[479, 'Headliner'] = 'Geographer'\n",
    "ticket_clean_df.loc[480, 'Headliner'] = 'New Pornographers'\n",
    "ticket_clean_df.loc[704, 'Headliner'] = 'Vince Staples'\n",
    "ticket_clean_df.loc[705, 'Headliner'] = 'Ty Segall'\n",
    "ticket_clean_df.loc[817, 'Headliner'] = 'Tune-Yards'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export `ticket_clean_df` to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_clean_df.to_csv(r'fox-theater-all-shows.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
